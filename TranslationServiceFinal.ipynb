{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0260171",
   "metadata": {},
   "source": [
    "# Translation Service\n",
    "\n",
    "### Authors: Mitchell Mahnke, Carter Shavitz, Kaden Young"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190c9e92",
   "metadata": {},
   "source": [
    "# Version 1: BERT (bad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5510a34",
   "metadata": {},
   "source": [
    "Our first pass at a translation service using BERT. This is a simple implementation that uses the BERT model to translate text from one english to spanish. The model is not very accurate and often produces nonsensical translations. Additionally it is notable that optima is used to optimize the tuning of the model hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b7c7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "from datasets import load_dataset, DatasetDict\n",
    "from transformers import (\n",
    "    BertTokenizerFast,\n",
    "    EncoderDecoderModel,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    Seq2SeqTrainer,\n",
    "    Seq2SeqTrainingArguments,\n",
    ")\n",
    "import optuna\n",
    "\n",
    "# ─── 1) SETUP LOGGING ──────────────────────────────────────────────────────────\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
    "    datefmt=\"%Y/%m/%d %H:%M:%S\",\n",
    "    level=logging.INFO,\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# ─── 2) LOAD & SPLIT EUROPARL EN–ES ────────────────────────────────────────────\n",
    "logger.info(\"Loading Europarl English–Spanish dataset…\")\n",
    "raw = load_dataset(\"europarl_bilingual\", \"en-es\")\n",
    "if \"validation\" not in raw:\n",
    "    logger.info(\"Creating a 10% validation split…\")\n",
    "    split = raw[\"train\"].train_test_split(test_size=0.1, seed=42)\n",
    "    raw = DatasetDict({\n",
    "        \"train\": split[\"train\"],\n",
    "        \"validation\": split[\"test\"],\n",
    "        \"test\": raw.get(\"test\",\n",
    "                        split[\"train\"].train_test_split(test_size=0.2, seed=42)[\"test\"])\n",
    "    })\n",
    "\n",
    "# ─── 3) SUBSAMPLE FOR SPEED ──────────────────────────────────────────────────\n",
    "max_train, max_val = 30_000, 3_000\n",
    "if len(raw[\"train\"]) > max_train:\n",
    "    raw[\"train\"] = raw[\"train\"].select(range(max_train))\n",
    "if len(raw[\"validation\"]) > max_val:\n",
    "    raw[\"validation\"] = raw[\"validation\"].select(range(max_val))\n",
    "\n",
    "# ─── 4) TOKENIZATION ──────────────────────────────────────────────────────────\n",
    "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-multilingual-cased\")\n",
    "max_len = 128\n",
    "\n",
    "def preprocess(batch, idxs):\n",
    "    logger.info(f\"Tokenizing examples {idxs[0]}–{idxs[-1]}…\")\n",
    "    inputs  = [t[\"en\"] for t in batch[\"translation\"]]\n",
    "    targets = [t[\"es\"] for t in batch[\"translation\"]]\n",
    "    enc = tokenizer(inputs,  max_length=max_len, truncation=True, padding=\"max_length\")\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        lbl = tokenizer(targets, max_length=max_len, truncation=True, padding=\"max_length\")\n",
    "    enc[\"labels\"] = lbl[\"input_ids\"]\n",
    "    return enc\n",
    "\n",
    "tokenized = raw.map(\n",
    "    preprocess,\n",
    "    batched=True,\n",
    "    batch_size=5000,\n",
    "    with_indices=True,\n",
    "    remove_columns=raw[\"train\"].column_names,\n",
    ")\n",
    "\n",
    "# ─── 5) DATA COLLATOR ─────────────────────────────────────────────────────────\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=None, padding=\"longest\")\n",
    "\n",
    "# ─── 6) MODEL INIT ────────────────────────────────────────────────────────────\n",
    "def model_init():\n",
    "    m = EncoderDecoderModel.from_encoder_decoder_pretrained(\n",
    "        \"bert-base-multilingual-cased\",\n",
    "        \"bert-base-multilingual-cased\",\n",
    "        tie_encoder_decoder=True,\n",
    "    )\n",
    "\n",
    "    # ─── Enable true seq2seq decoder with cross‐attention:\n",
    "    m.config.decoder.is_decoder        = True\n",
    "    m.config.decoder.add_cross_attention = True\n",
    "\n",
    "    # ─── Special tokens & lengths\n",
    "    m.config.decoder_start_token_id = tokenizer.cls_token_id\n",
    "    m.config.eos_token_id           = tokenizer.sep_token_id\n",
    "    m.config.pad_token_id           = tokenizer.pad_token_id\n",
    "    m.config.max_length             = 128\n",
    "    m.config.min_length             = 10\n",
    "    m.config.no_repeat_ngram_size   = 3\n",
    "\n",
    "    return m\n",
    "\n",
    "# ─── 7) HYPERPARAMETER SPACE ─────────────────────────────────────────────────\n",
    "def hp_space(trial: optuna.Trial):\n",
    "    return {\n",
    "        \"learning_rate\":               trial.suggest_loguniform(\"learning_rate\", 1e-6, 5e-5),\n",
    "        # smaller batch‐size choices to avoid OOM\n",
    "        \"per_device_train_batch_size\": trial.suggest_categorical(\n",
    "            \"per_device_train_batch_size\", [4, 8, 16]\n",
    "        ),\n",
    "        \"weight_decay\":                trial.suggest_uniform(\"weight_decay\", 0.0, 0.3),\n",
    "        \"warmup_steps\":                trial.suggest_int(\"warmup_steps\", 0, 1000),\n",
    "        \"num_train_epochs\":            trial.suggest_categorical(\"num_train_epochs\", [2, 3, 4]),\n",
    "    }\n",
    "\n",
    "# ─── 8) TUNING ARGS ────────────────────────────────────────────────────────────\n",
    "tuning_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./hp_tuning\",\n",
    "    per_device_train_batch_size=8,      # default, overridden in hp_space\n",
    "    per_device_eval_batch_size=8,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=500,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=500,\n",
    "    save_total_limit=3,\n",
    "    logging_steps=100,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "\n",
    "    # Use HF’s Torch AdamW\n",
    "    optim=\"adamw_torch\",\n",
    "\n",
    "    # Temporarily disable mixed precision until HPO+AMP bug is fixed\n",
    "    fp16=False,\n",
    ")\n",
    "\n",
    "# ─── 9) TRAINER & HPO RUN ─────────────────────────────────────────────────────\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model_init      = model_init,\n",
    "    args            = tuning_args,\n",
    "    train_dataset   = tokenized[\"train\"],\n",
    "    eval_dataset    = tokenized[\"validation\"],\n",
    "    data_collator   = data_collator,\n",
    "    tokenizer       = tokenizer,\n",
    "    compute_metrics = None,  # replace with your BLEU fn if desired\n",
    ")\n",
    "\n",
    "best = trainer.hyperparameter_search(\n",
    "    direction=\"minimize\",\n",
    "    backend=\"optuna\",\n",
    "    hp_space=hp_space,\n",
    "    n_trials=20,\n",
    "    n_jobs=1,                       \n",
    "    pruner=optuna.pruners.MedianPruner(),\n",
    "    study_name=\"bert_translation_hp\",\n",
    ")\n",
    "\n",
    "print(\"Best hyperparameters:\", best.hyperparameters)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a667a79",
   "metadata": {},
   "source": [
    "# Version 2: Encoder + Decoder transition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6ad53f",
   "metadata": {},
   "source": [
    "In this second attempt, a more sophisticated approach is taken. The model is now a sequence-to-sequence model that uses an encoder-decoder architecture. The encoder processes the input text and generates a context vector, which is then passed to the decoder to generate the output text. This approach allows for more accurate translations and better handling of long sentences. The model is trained on a large dataset of English-Spanish sentence pairs, and uses attention mechanisms to focus on relevant parts of the input when generating the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cb43fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datasets import load_dataset, DatasetDict\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    Seq2SeqTrainer,\n",
    "    Seq2SeqTrainingArguments,\n",
    ")\n",
    "import evaluate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6123d57d",
   "metadata": {},
   "source": [
    "## Set up logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4099ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
    "    datefmt=\"%Y/%m/%d %H:%M:%S\",\n",
    "    level=logging.INFO,\n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ca0774",
   "metadata": {},
   "source": [
    "## Load & split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4411f437",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"Loading Europarl English-Spanish dataset…\")\n",
    "raw = load_dataset(\"europarl_bilingual\", \"en-es\")\n",
    "if \"validation\" not in raw:\n",
    "    logger.info(\"Creating a 10% validation split…\")\n",
    "    split = raw[\"train\"].train_test_split(test_size=0.1, seed=42)\n",
    "    raw = DatasetDict({\n",
    "        \"train\": split[\"train\"],\n",
    "        \"validation\": split[\"test\"],\n",
    "        \"test\": raw.get(\n",
    "            \"test\",\n",
    "            split[\"train\"].train_test_split(test_size=0.2, seed=42)[\"test\"]\n",
    "        ),\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18b10b0",
   "metadata": {},
   "source": [
    "## Subsample the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7070fd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "frac = 0.01   # keep only 10% of each split\n",
    "seed = 42\n",
    "for split_name in (\"train\", \"validation\", \"test\"):\n",
    "    ds = raw[split_name].shuffle(seed=seed)\n",
    "    n = max(1, int(len(ds) * frac))\n",
    "    logger.info(\n",
    "        f\"Subsampling {n} examples ({frac*100:.2f}%) from '{split_name}' \"\n",
    "        f\"({len(ds)} total)…\"\n",
    "    )\n",
    "    raw[split_name] = ds.select(range(n))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119cf7ec",
   "metadata": {},
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a14d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"Helsinki-NLP/opus-mt-en-es\"\n",
    "logger.info(f\"Loading tokenizer and model: {MODEL_NAME}\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1abc55c",
   "metadata": {},
   "source": [
    "## Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0e48a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 128\n",
    "def preprocess(batch):\n",
    "    inputs= [t[\"en\"] for t in batch[\"translation\"]]\n",
    "    targets = [t[\"es\"] for t in batch[\"translation\"]]\n",
    "    encodings = tokenizer(\n",
    "        inputs, max_length=max_len, truncation=True, padding=\"max_length\"\n",
    "    )\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(\n",
    "            targets, max_length=max_len, truncation=True, padding=\"max_length\"\n",
    "        )\n",
    "    encodings[\"labels\"] = labels[\"input_ids\"]\n",
    "    return encodings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca71cbe7",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1872dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"Tokenizing dataset with fast mapping…\")\n",
    "tokenized = raw.map(\n",
    "    preprocess,\n",
    "    batched=True,\n",
    "    batch_size=2000,\n",
    "    num_proc=4,\n",
    "    remove_columns=raw[\"train\"].column_names,\n",
    "    load_from_cache_file=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6333b6dc",
   "metadata": {},
   "source": [
    "## Compute dynamic evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5f1b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bs = 16\n",
    "grad_accum = 2\n",
    "epochs = 3\n",
    "\n",
    "num_samples = len(tokenized[\"train\"])\n",
    "steps_per_epoch = math.ceil(num_samples / (train_bs * grad_accum))\n",
    "total_steps = steps_per_epoch * epochs\n",
    "eval_interval= max(1, total_steps // 20)\n",
    "logger.info(f\"Total training steps ≃ {total_steps}, will eval every {eval_interval} steps\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39fbf90",
   "metadata": {},
   "source": [
    "## Data collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b802e2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME)\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, padding=\"longest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0f74b9",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a29270",
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu = evaluate.load(\"bleu\")\n",
    "def compute_metrics(eval_pred):\n",
    "    preds, labels = eval_pred\n",
    "    decoded_preds = tokenizer.batch_decode(preds,  skip_special_tokens=True)\n",
    "    decoded_labels= tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    result = bleu.compute(\n",
    "        predictions=decoded_preds,\n",
    "        references=[[l] for l in decoded_labels]\n",
    "    )\n",
    "    result[\"bleu\"] *= 100\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b06f08",
   "metadata": {},
   "source": [
    "## Training & args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aab30a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ─── 9) TRAINING ARGUMENTS (modern eval + slower LR + dynamic eval + initial eval) ─\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./checkpoints\",\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    eval_on_start=True,\n",
    "    # dynamic evaluation cadence during training\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=eval_interval,\n",
    "    # logging on same cadence\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=eval_interval,\n",
    "    # checkpointing every 500 steps\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=500,\n",
    "    save_total_limit=3,\n",
    "    # batching\n",
    "    per_device_train_batch_size=train_bs,\n",
    "    per_device_eval_batch_size=16,\n",
    "    gradient_accumulation_steps=grad_accum,\n",
    "    # mixed‑precision\n",
    "    fp16=True,\n",
    "    # slow down learning\n",
    "    learning_rate=1e-5,\n",
    "    warmup_steps=50,\n",
    "    lr_scheduler_type=\"linear\",\n",
    "    weight_decay=0.01,\n",
    "    optim=\"adamw_torch\",\n",
    "    num_train_epochs=epochs,\n",
    "    # generation\n",
    "    predict_with_generate=True,\n",
    "    generation_max_length=max_len,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2acd6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized[\"train\"],\n",
    "    eval_dataset=tokenized[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c694e3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"Starting training...\")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c7b610",
   "metadata": {},
   "source": [
    "## Loss metrics from logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb05bf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_history = trainer.state.log_history\n",
    "train_logs  = [e for e in log_history if \"loss\" in e and \"eval_loss\" not in e and \"step\" in e]\n",
    "train_steps = [e[\"step\"] for e in train_logs]\n",
    "train_losses= [e[\"loss\"] for e in train_logs]\n",
    "\n",
    "eval_logs   = [e for e in log_history if \"eval_loss\" in e]\n",
    "eval_steps  = [e[\"step\"]      for e in eval_logs]\n",
    "val_losses  = [e[\"eval_loss\"] for e in eval_logs]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8022d4c",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebeefba",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scores = trainer.evaluate(tokenized[\"test\"])\n",
    "test_loss   = test_scores.get(\"eval_loss\", test_scores.get(\"loss\", 0.0))\n",
    "logger.info(f\"Test Loss: {test_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270fedb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for step, loss in zip(eval_steps, val_losses):\n",
    "    logger.info(f\"Validation loss at step {step}: {loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d7fb62",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7816f2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(train_steps, train_losses, marker=\"o\", label=\"Train Loss\")\n",
    "plt.plot(eval_steps,  val_losses,   marker=\"o\", label=\"Validation Loss\")\n",
    "plt.axhline(test_loss, linestyle=\"--\", label=f\"Test Loss ({test_loss:.4f})\")\n",
    "plt.title(\"Train, Validation, and Test Loss Over Steps\")\n",
    "plt.xlabel(\"Step\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(\"all_loss_curves.png\")\n",
    "plt.show()\n",
    "plt.close()\n",
    "logger.info(\"Saved all_loss_curves.png\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
